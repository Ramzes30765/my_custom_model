{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "from neck.attention_bifpn import BiFPN\n",
    "from heads.dynamic_head import DynamicHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bifpn = BiFPN(\n",
    "    backbone='resnet18',\n",
    "    out_channels=256,\n",
    "    num_layers=2,\n",
    "    use_lateral_cbam=True,\n",
    "    use_td_cbam=True,\n",
    "    use_skconv=True,\n",
    "    use_aac=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 640, 480)\n",
    "y = bifpn(x)\n",
    "# for i in y:\n",
    "#     print(i.shape)\n",
    "#     print(i.requires_grad)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.2612e-02,  1.1865e-02,  1.2128e-02,  ...,  1.4165e-02,\n",
       "             5.5325e-03,  9.7289e-03],\n",
       "           [ 1.1071e-02,  9.2240e-03,  9.4279e-03,  ...,  8.1283e-03,\n",
       "            -8.0190e-04,  8.4616e-03],\n",
       "           [ 1.0692e-02,  9.8105e-03,  1.3091e-02,  ...,  5.0467e-03,\n",
       "             1.8950e-03,  1.1640e-02],\n",
       "           ...,\n",
       "           [ 1.0930e-02,  6.2795e-03,  1.0500e-03,  ...,  1.2371e-02,\n",
       "             4.9634e-03,  8.0262e-03],\n",
       "           [ 9.6139e-03,  6.3554e-03,  4.3816e-03,  ...,  7.1352e-03,\n",
       "             5.0257e-03,  9.4785e-03],\n",
       "           [ 9.6591e-03,  7.7190e-03,  7.0970e-03,  ...,  4.1322e-03,\n",
       "             9.3570e-03,  9.9227e-03]],\n",
       " \n",
       "          [[ 4.3538e-03,  3.6122e-03,  2.3658e-03,  ...,  5.2624e-03,\n",
       "             4.9462e-03,  4.4635e-03],\n",
       "           [ 5.0158e-03,  5.3370e-03,  3.5851e-03,  ...,  3.4328e-03,\n",
       "             7.2592e-03,  3.8904e-03],\n",
       "           [ 3.2967e-03,  1.5093e-03,  3.5654e-03,  ...,  3.1109e-03,\n",
       "             1.0496e-02,  6.9217e-03],\n",
       "           ...,\n",
       "           [ 7.5329e-04,  1.7762e-03, -6.9432e-04,  ..., -6.9952e-03,\n",
       "             3.2748e-03,  5.0091e-03],\n",
       "           [ 1.2070e-03,  4.6767e-03,  3.2252e-03,  ..., -2.4077e-03,\n",
       "            -1.4549e-03,  4.5369e-03],\n",
       "           [ 3.0479e-03,  4.9972e-03,  9.0338e-03,  ...,  8.2356e-03,\n",
       "             8.6642e-03,  7.2255e-03]],\n",
       " \n",
       "          [[ 9.3063e-04,  1.2694e-03,  8.5166e-04,  ...,  1.8420e-03,\n",
       "             8.8131e-04,  1.5573e-03],\n",
       "           [ 1.9750e-03,  4.7718e-03,  3.7260e-03,  ...,  3.5152e-03,\n",
       "             2.6957e-04, -1.7949e-03],\n",
       "           [ 1.5386e-03,  1.2073e-03,  3.4570e-03,  ...,  3.7907e-03,\n",
       "             1.4371e-04, -1.6335e-03],\n",
       "           ...,\n",
       "           [ 7.6699e-04,  2.2745e-03, -2.6971e-03,  ...,  1.2109e-03,\n",
       "            -6.1146e-04,  6.9600e-05],\n",
       "           [ 1.5364e-03,  8.3749e-04,  2.9737e-04,  ...,  1.6051e-03,\n",
       "             1.9446e-03, -1.4371e-03],\n",
       "           [ 1.0209e-03,  9.1006e-04,  1.2513e-03,  ..., -1.5913e-03,\n",
       "            -7.8167e-04,  7.9153e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7616e-02,  1.7965e-02,  1.8584e-02,  ...,  1.3993e-02,\n",
       "             1.6723e-02,  2.2256e-02],\n",
       "           [ 1.7933e-02,  2.2136e-02,  2.2605e-02,  ...,  1.9510e-02,\n",
       "             1.7665e-02,  2.0995e-02],\n",
       "           [ 1.8522e-02,  2.0447e-02,  1.8085e-02,  ...,  2.1696e-02,\n",
       "             1.8082e-02,  2.0987e-02],\n",
       "           ...,\n",
       "           [ 1.8556e-02,  1.8305e-02,  1.4609e-02,  ...,  2.0372e-02,\n",
       "             2.3724e-02,  2.3231e-02],\n",
       "           [ 1.9587e-02,  1.5942e-02,  1.4716e-02,  ...,  1.4601e-02,\n",
       "             1.6783e-02,  2.1153e-02],\n",
       "           [ 1.9384e-02,  1.9830e-02,  2.0000e-02,  ...,  1.4885e-02,\n",
       "             1.6084e-02,  1.8754e-02]],\n",
       " \n",
       "          [[ 6.1064e-03,  5.1722e-03,  5.2248e-03,  ...,  5.5459e-04,\n",
       "             2.1645e-03,  4.4157e-03],\n",
       "           [ 7.9029e-03,  4.2919e-03,  3.7019e-03,  ...,  1.8119e-03,\n",
       "             2.3423e-03,  1.7593e-03],\n",
       "           [ 6.1841e-03,  4.3138e-03,  5.6103e-03,  ..., -1.4495e-03,\n",
       "             4.9274e-04,  3.0218e-03],\n",
       "           ...,\n",
       "           [ 4.3281e-03, -5.5181e-04, -2.1681e-03,  ...,  1.4818e-03,\n",
       "             3.9636e-04, -3.7036e-03],\n",
       "           [ 5.5079e-03,  1.9523e-03, -6.6530e-04,  ...,  1.0232e-03,\n",
       "            -4.2533e-03, -4.1813e-03],\n",
       "           [ 7.2286e-03,  2.5643e-03,  4.3426e-03,  ...,  5.7618e-03,\n",
       "             7.9509e-03,  3.3707e-03]],\n",
       " \n",
       "          [[ 4.9237e-03,  3.6490e-03,  3.8827e-03,  ...,  3.4821e-03,\n",
       "             6.0921e-03,  7.7344e-03],\n",
       "           [ 5.7760e-03,  4.9560e-03,  5.6983e-03,  ...,  6.0542e-03,\n",
       "             9.4088e-03,  1.1956e-02],\n",
       "           [ 6.0735e-03,  5.1247e-03,  6.2060e-03,  ...,  2.9288e-03,\n",
       "             7.0129e-03,  1.1813e-02],\n",
       "           ...,\n",
       "           [ 5.6830e-03,  6.8557e-03,  7.7187e-03,  ...,  1.3298e-03,\n",
       "             9.8320e-04,  8.3244e-03],\n",
       "           [ 5.8440e-03,  8.9104e-03,  1.3419e-02,  ...,  1.1029e-02,\n",
       "             1.3363e-02,  1.0429e-02],\n",
       "           [ 4.0986e-03,  1.0135e-02,  9.7605e-03,  ...,  8.1915e-03,\n",
       "             7.1638e-03,  8.6678e-03]]]], grad_fn=<ConvolutionBackward0>),\n",
       " tensor([[[[ 0.0453,  0.0768,  0.0760,  ...,  0.0763,  0.0767,  0.0978],\n",
       "           [ 0.0958,  0.1413,  0.1406,  ...,  0.1403,  0.1402,  0.1412],\n",
       "           [ 0.0970,  0.1430,  0.1413,  ...,  0.1414,  0.1405,  0.1410],\n",
       "           ...,\n",
       "           [ 0.0978,  0.1435,  0.1429,  ...,  0.1421,  0.1416,  0.1415],\n",
       "           [ 0.0985,  0.1447,  0.1441,  ...,  0.1435,  0.1434,  0.1425],\n",
       "           [ 0.0564,  0.0844,  0.0836,  ...,  0.0838,  0.0834,  0.0618]],\n",
       " \n",
       "          [[-0.0652, -0.0984, -0.0980,  ..., -0.0983, -0.0976, -0.0441],\n",
       "           [-0.0875, -0.0481, -0.0479,  ..., -0.0480, -0.0471,  0.0250],\n",
       "           [-0.0874, -0.0479, -0.0483,  ..., -0.0485, -0.0475,  0.0246],\n",
       "           ...,\n",
       "           [-0.0875, -0.0479, -0.0485,  ..., -0.0488, -0.0474,  0.0243],\n",
       "           [-0.0876, -0.0482, -0.0486,  ..., -0.0481, -0.0474,  0.0241],\n",
       "           [-0.0848, -0.0200, -0.0209,  ..., -0.0203, -0.0199,  0.0354]],\n",
       " \n",
       "          [[-0.0235,  0.0705,  0.0706,  ...,  0.0709,  0.0712,  0.0864],\n",
       "           [-0.0314,  0.1156,  0.1159,  ...,  0.1157,  0.1159,  0.1225],\n",
       "           [-0.0314,  0.1157,  0.1154,  ...,  0.1157,  0.1159,  0.1223],\n",
       "           ...,\n",
       "           [-0.0313,  0.1151,  0.1154,  ...,  0.1154,  0.1157,  0.1227],\n",
       "           [-0.0314,  0.1145,  0.1146,  ...,  0.1148,  0.1149,  0.1221],\n",
       "           [-0.0119,  0.0790,  0.0783,  ...,  0.0787,  0.0788,  0.0906]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.1012,  0.0740,  0.0744,  ...,  0.0747,  0.0740,  0.0686],\n",
       "           [ 0.1435,  0.1117,  0.1118,  ...,  0.1122,  0.1113,  0.0868],\n",
       "           [ 0.1435,  0.1122,  0.1129,  ...,  0.1115,  0.1113,  0.0866],\n",
       "           ...,\n",
       "           [ 0.1446,  0.1135,  0.1138,  ...,  0.1136,  0.1127,  0.0872],\n",
       "           [ 0.1441,  0.1125,  0.1123,  ...,  0.1123,  0.1117,  0.0866],\n",
       "           [ 0.0611,  0.0363,  0.0362,  ...,  0.0359,  0.0356,  0.0071]],\n",
       " \n",
       "          [[ 0.0360,  0.0464,  0.0460,  ...,  0.0455,  0.0452,  0.0261],\n",
       "           [ 0.0242,  0.0727,  0.0720,  ...,  0.0718,  0.0718,  0.0795],\n",
       "           [ 0.0235,  0.0722,  0.0718,  ...,  0.0721,  0.0731,  0.0805],\n",
       "           ...,\n",
       "           [ 0.0228,  0.0717,  0.0713,  ...,  0.0717,  0.0722,  0.0798],\n",
       "           [ 0.0228,  0.0721,  0.0725,  ...,  0.0732,  0.0739,  0.0807],\n",
       "           [-0.0326,  0.0002,  0.0005,  ...,  0.0004,  0.0009,  0.0438]],\n",
       " \n",
       "          [[-0.0201, -0.0414, -0.0423,  ..., -0.0422, -0.0422, -0.0239],\n",
       "           [-0.0332, -0.0636, -0.0639,  ..., -0.0646, -0.0636, -0.0104],\n",
       "           [-0.0329, -0.0635, -0.0623,  ..., -0.0633, -0.0621, -0.0093],\n",
       "           ...,\n",
       "           [-0.0320, -0.0626, -0.0616,  ..., -0.0621, -0.0610, -0.0091],\n",
       "           [-0.0322, -0.0624, -0.0614,  ..., -0.0618, -0.0605, -0.0085],\n",
       "           [-0.0557, -0.0951, -0.0939,  ..., -0.0946, -0.0930, -0.0386]]]],\n",
       "        grad_fn=<ConvolutionBackward0>),\n",
       " tensor([[[[-4.4713e-02, -6.5634e-02, -6.3654e-02,  ..., -6.3242e-02,\n",
       "            -6.0425e-02, -4.0122e-02],\n",
       "           [-8.5045e-02, -1.9258e-01, -1.8952e-01,  ..., -1.8905e-01,\n",
       "            -1.8472e-01, -1.5011e-01],\n",
       "           [-8.2534e-02, -1.9369e-01, -1.8953e-01,  ..., -1.8934e-01,\n",
       "            -1.8728e-01, -1.5328e-01],\n",
       "           ...,\n",
       "           [-8.2119e-02, -1.9428e-01, -1.9151e-01,  ..., -1.8964e-01,\n",
       "            -1.8809e-01, -1.5362e-01],\n",
       "           [-8.1953e-02, -1.9446e-01, -1.9196e-01,  ..., -1.8947e-01,\n",
       "            -1.8861e-01, -1.5292e-01],\n",
       "           [-6.1670e-02, -1.5463e-01, -1.5347e-01,  ..., -1.5050e-01,\n",
       "            -1.5060e-01, -1.2469e-01]],\n",
       " \n",
       "          [[-4.5289e-02, -3.0623e-02, -2.9163e-02,  ..., -3.3934e-02,\n",
       "            -3.6421e-02,  3.0427e-03],\n",
       "           [-7.3593e-02, -5.3867e-02, -5.6153e-02,  ..., -5.9265e-02,\n",
       "            -6.0727e-02, -5.0564e-03],\n",
       "           [-7.1179e-02, -4.9833e-02, -5.3560e-02,  ..., -5.8554e-02,\n",
       "            -6.0774e-02, -6.7385e-03],\n",
       "           ...,\n",
       "           [-7.1893e-02, -5.1145e-02, -5.4208e-02,  ..., -5.9527e-02,\n",
       "            -6.0214e-02, -6.4820e-03],\n",
       "           [-6.6417e-02, -4.3992e-02, -4.9164e-02,  ..., -5.3759e-02,\n",
       "            -5.3910e-02, -6.2291e-03],\n",
       "           [-3.4088e-02,  1.5053e-02,  1.2578e-02,  ...,  1.0258e-02,\n",
       "             9.9124e-03,  3.0864e-02]],\n",
       " \n",
       "          [[ 1.5835e-02, -3.2379e-02, -2.9076e-02,  ..., -2.9649e-02,\n",
       "            -2.5984e-02, -9.7630e-02],\n",
       "           [ 5.0803e-02,  3.3482e-03,  8.3615e-03,  ...,  8.0636e-03,\n",
       "             9.4178e-03, -6.8070e-02],\n",
       "           [ 4.8771e-02,  3.3919e-04,  7.2472e-03,  ...,  6.3090e-03,\n",
       "             7.9730e-03, -7.0181e-02],\n",
       "           ...,\n",
       "           [ 4.9467e-02,  1.6726e-04,  7.7721e-03,  ...,  2.3383e-03,\n",
       "             3.6865e-03, -7.3692e-02],\n",
       "           [ 5.6062e-02,  6.9870e-03,  1.3534e-02,  ...,  7.9991e-03,\n",
       "             6.5526e-03, -7.5475e-02],\n",
       "           [-1.3239e-02, -4.0008e-02, -3.6227e-02,  ..., -4.0510e-02,\n",
       "            -4.0865e-02, -7.1733e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5737e-02, -1.3366e-02, -1.3216e-02,  ..., -1.4987e-02,\n",
       "            -1.3226e-02, -8.6213e-04],\n",
       "           [-1.1775e-02,  8.6571e-03,  9.0467e-03,  ...,  7.5179e-03,\n",
       "             1.1782e-02,  3.1834e-02],\n",
       "           [-9.8055e-03,  1.3360e-02,  1.5317e-02,  ...,  1.6647e-02,\n",
       "             2.1192e-02,  4.0054e-02],\n",
       "           ...,\n",
       "           [-8.1758e-03,  1.6239e-02,  1.8241e-02,  ...,  1.7893e-02,\n",
       "             2.2362e-02,  4.0185e-02],\n",
       "           [-4.6043e-03,  2.1781e-02,  2.3230e-02,  ...,  2.4353e-02,\n",
       "             2.7264e-02,  4.3396e-02],\n",
       "           [-6.1883e-04,  2.2726e-02,  2.3824e-02,  ...,  2.4788e-02,\n",
       "             2.6225e-02,  1.3571e-02]],\n",
       " \n",
       "          [[ 6.2493e-02,  2.4138e-02,  1.8657e-02,  ...,  2.1260e-02,\n",
       "             1.7463e-02, -1.9285e-02],\n",
       "           [ 5.9669e-02,  6.4501e-03,  5.6979e-03,  ...,  9.9957e-03,\n",
       "             5.8664e-03, -3.6171e-02],\n",
       "           [ 5.9490e-02,  2.6120e-03,  3.5942e-03,  ...,  6.8496e-03,\n",
       "             3.2429e-03, -3.7674e-02],\n",
       "           ...,\n",
       "           [ 5.8070e-02,  2.0858e-03,  3.6140e-03,  ...,  7.3823e-03,\n",
       "             4.5865e-03, -3.7083e-02],\n",
       "           [ 5.2729e-02, -5.1548e-03, -3.0678e-03,  ...,  6.8506e-06,\n",
       "             1.2330e-04, -4.0054e-02],\n",
       "           [ 8.6115e-02,  5.8825e-02,  6.3635e-02,  ...,  6.3699e-02,\n",
       "             6.3911e-02,  1.1057e-03]],\n",
       " \n",
       "          [[-1.0565e-02, -5.6337e-02, -5.5807e-02,  ..., -5.5537e-02,\n",
       "            -5.0432e-02, -4.1651e-03],\n",
       "           [-4.2345e-02, -1.0764e-01, -1.0990e-01,  ..., -1.0947e-01,\n",
       "            -1.0628e-01, -5.2499e-02],\n",
       "           [-4.2754e-02, -1.0970e-01, -1.1336e-01,  ..., -1.1166e-01,\n",
       "            -1.0829e-01, -5.4201e-02],\n",
       "           ...,\n",
       "           [-3.9759e-02, -1.0625e-01, -1.0896e-01,  ..., -1.1029e-01,\n",
       "            -1.0568e-01, -5.5470e-02],\n",
       "           [-4.0128e-02, -1.0469e-01, -1.0934e-01,  ..., -1.1077e-01,\n",
       "            -1.0744e-01, -5.7407e-02],\n",
       "           [-3.9464e-02, -8.6868e-02, -8.8380e-02,  ..., -8.9985e-02,\n",
       "            -9.0433e-02, -3.9119e-02]]]], grad_fn=<ConvolutionBackward0>),\n",
       " tensor([[[[ 0.0373,  0.1044,  0.0994,  ...,  0.1020,  0.1005,  0.0889],\n",
       "           [ 0.0195,  0.0735,  0.0674,  ...,  0.0654,  0.0659,  0.0659],\n",
       "           [ 0.0161,  0.0681,  0.0680,  ...,  0.0613,  0.0641,  0.0684],\n",
       "           ...,\n",
       "           [ 0.0146,  0.0747,  0.0691,  ...,  0.0630,  0.0642,  0.0618],\n",
       "           [ 0.0074,  0.0628,  0.0619,  ...,  0.0555,  0.0597,  0.0591],\n",
       "           [-0.0243, -0.0053, -0.0007,  ..., -0.0044,  0.0013,  0.0013]],\n",
       " \n",
       "          [[ 0.0315,  0.0238,  0.0275,  ...,  0.0339,  0.0403, -0.0156],\n",
       "           [-0.0056,  0.0026,  0.0082,  ...,  0.0141,  0.0186, -0.0127],\n",
       "           [-0.0090,  0.0027,  0.0046,  ...,  0.0122,  0.0178, -0.0131],\n",
       "           ...,\n",
       "           [-0.0006,  0.0064,  0.0093,  ...,  0.0156,  0.0184, -0.0150],\n",
       "           [-0.0053,  0.0030,  0.0027,  ...,  0.0089,  0.0103, -0.0186],\n",
       "           [-0.0154, -0.0131, -0.0146,  ..., -0.0139, -0.0140, -0.0469]],\n",
       " \n",
       "          [[ 0.0999,  0.0997,  0.0930,  ...,  0.0915,  0.0881,  0.0540],\n",
       "           [ 0.0473,  0.0412,  0.0410,  ...,  0.0386,  0.0319,  0.0246],\n",
       "           [ 0.0447,  0.0404,  0.0403,  ...,  0.0373,  0.0335,  0.0280],\n",
       "           ...,\n",
       "           [ 0.0472,  0.0404,  0.0408,  ...,  0.0391,  0.0390,  0.0285],\n",
       "           [ 0.0521,  0.0485,  0.0487,  ...,  0.0470,  0.0434,  0.0329],\n",
       "           [ 0.0282,  0.0313,  0.0367,  ...,  0.0380,  0.0338,  0.0435]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0853,  0.0529,  0.0555,  ...,  0.0533,  0.0457, -0.0275],\n",
       "           [ 0.0738,  0.0794,  0.0840,  ...,  0.0800,  0.0708, -0.0004],\n",
       "           [ 0.0756,  0.0840,  0.0887,  ...,  0.0884,  0.0784,  0.0047],\n",
       "           ...,\n",
       "           [ 0.0705,  0.0811,  0.0854,  ...,  0.0865,  0.0817,  0.0082],\n",
       "           [ 0.0691,  0.0803,  0.0855,  ...,  0.0846,  0.0811,  0.0081],\n",
       "           [ 0.0216,  0.0477,  0.0470,  ...,  0.0527,  0.0506,  0.0156]],\n",
       " \n",
       "          [[ 0.0599,  0.0636,  0.0593,  ...,  0.0593,  0.0532,  0.0143],\n",
       "           [ 0.0187,  0.0483,  0.0476,  ...,  0.0513,  0.0494,  0.0355],\n",
       "           [ 0.0165,  0.0466,  0.0468,  ...,  0.0530,  0.0524,  0.0363],\n",
       "           ...,\n",
       "           [ 0.0176,  0.0489,  0.0530,  ...,  0.0611,  0.0594,  0.0406],\n",
       "           [ 0.0128,  0.0421,  0.0467,  ...,  0.0584,  0.0617,  0.0407],\n",
       "           [ 0.0166,  0.0087,  0.0124,  ...,  0.0234,  0.0253,  0.0203]],\n",
       " \n",
       "          [[-0.0907, -0.1396, -0.1364,  ..., -0.1405, -0.1431, -0.0740],\n",
       "           [ 0.0048, -0.0895, -0.0883,  ..., -0.0911, -0.0931, -0.0763],\n",
       "           [ 0.0108, -0.0896, -0.0838,  ..., -0.0904, -0.0910, -0.0793],\n",
       "           ...,\n",
       "           [ 0.0047, -0.0914, -0.0867,  ..., -0.0927, -0.0924, -0.0765],\n",
       "           [ 0.0002, -0.0899, -0.0869,  ..., -0.0916, -0.0869, -0.0749],\n",
       "           [ 0.0535, -0.0197, -0.0139,  ..., -0.0139, -0.0103, -0.0424]]]],\n",
       "        grad_fn=<ConvolutionBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                  Torch-Compiled Region        55.53%        6.108s        69.14%        7.606s      63.380ms        6.080s        55.28%        8.280s      69.002ms           0 b      -3.28 Kb      19.21 Mb    -714.00 Kb           120  \n",
      "                                        model_inference         7.53%     828.348ms       100.00%       11.000s       11.000s     705.009ms         6.41%       11.000s       11.000s           0 b           0 b    -532.95 Mb     -14.82 Gb             1  \n",
      "                                FlexAttentionAutogradOp         3.83%     420.948ms        10.44%        1.149s       9.572ms     379.568ms         3.45%        1.821s      15.179ms           0 b        -480 b      19.38 Mb     -62.79 Gb           120  \n",
      "                                aten::cudnn_convolution         1.17%     128.708ms         1.47%     162.026ms     109.477us     359.164ms         3.27%     394.985ms     266.882us           0 b           0 b       3.09 Gb       2.29 Gb          1480  \n",
      "                                            aten::where         0.77%      85.025ms         1.47%     161.954ms     224.937us     246.330ms         2.24%     300.798ms     417.775us           0 b           0 b      29.36 Gb    -119.00 Kb           720  \n",
      "                                    aten::empty_strided         2.05%     225.118ms         2.10%     230.891ms      83.747us     234.862ms         2.14%     257.355ms      93.346us         956 b         956 b     539.50 Kb     539.50 Kb          2757  \n",
      "                                              aten::bmm         0.22%      23.897ms         0.22%      23.897ms      99.571us     192.430ms         1.75%     192.430ms     801.792us           0 b           0 b      14.70 Gb      14.70 Gb           240  \n",
      "                                       aten::index_put_         0.77%      84.811ms        12.71%        1.398s       3.883ms     166.597ms         1.51%     825.588ms       2.293ms           0 b      -1.88 Kb           0 b     -60.00 Kb           360  \n",
      "                                              aten::mul         0.38%      42.031ms         0.38%      42.031ms      37.528us     156.899ms         1.43%     156.899ms     140.088us           0 b           0 b      20.47 Gb      20.47 Gb          1120  \n",
      "                                         aten::_softmax         0.14%      15.756ms         0.14%      15.756ms      32.826us     121.287ms         1.10%     121.287ms     252.681us           0 b           0 b      14.67 Gb      14.67 Gb           480  \n",
      "                                               aten::eq         0.11%      12.029ms         0.11%      12.029ms      33.415us     116.385ms         1.06%     116.385ms     323.292us           0 b           0 b       7.33 Gb       7.33 Gb           360  \n",
      "                                            aten::empty         0.40%      44.418ms         0.40%      44.418ms       6.206us     108.800ms         0.99%     108.800ms      15.202us       2.81 Kb       2.81 Kb       1.99 Gb       1.99 Gb          7157  \n",
      "                                            aten::copy_         6.07%     667.388ms         6.07%     667.388ms     327.151us      98.888ms         0.90%      98.888ms      48.475us           0 b           0 b           0 b           0 b          2040  \n",
      "                                           aten::expand         1.82%     200.402ms         2.21%     242.623ms     106.414us      98.826ms         0.90%     144.954ms      63.576us           0 b           0 b           0 b           0 b          2280  \n",
      "                                              aten::sub         0.04%       3.982ms         0.04%       3.982ms      33.182us      91.905ms         0.84%      91.905ms     765.875us           0 b           0 b      14.67 Gb      14.67 Gb           120  \n",
      "                                           aten::arange         1.38%     151.406ms         1.99%     219.071ms     101.422us      90.443ms         0.82%     188.225ms      87.141us       3.75 Kb           0 b       8.32 Mb           0 b          2160  \n",
      "                                       aten::as_strided         0.16%      17.721ms         0.16%      17.721ms       2.504us      85.630ms         0.78%      85.630ms      12.101us           0 b           0 b           0 b           0 b          7076  \n",
      "                                             aten::exp_         0.02%       2.553ms         0.02%       2.553ms      21.279us      80.647ms         0.73%      80.647ms     672.058us           0 b           0 b           0 b           0 b           120  \n",
      "                                              aten::sum         0.34%      37.942ms         0.49%      54.369ms     113.269us      78.946ms         0.72%     101.534ms     211.529us           0 b           0 b     497.99 Mb     494.06 Mb           480  \n",
      "                                 aten::cudnn_batch_norm         0.83%      91.362ms         1.04%     114.706ms     286.764us      75.074ms         0.68%     123.314ms     308.285us           0 b           0 b       1.14 Gb           0 b           400  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 11.000s\n",
      "Self CUDA time total: 11.000s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bifpn.to(device)\n",
    "bifpn.train()\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 640, 480, device=device)\n",
    "n_runs = 20\n",
    "\n",
    "for _ in range(10):\n",
    "    _ = bifpn(dummy_input)\n",
    "\n",
    "# Запускаем профайлер\n",
    "with torch.profiler.profile(\n",
    "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "    record_shapes=True,      # Записывать информацию о формах тензоров\n",
    "    profile_memory=True,     # Отслеживать использование памяти\n",
    "    with_stack=True           # Сохранять стек вызовов\n",
    ") as prof:\n",
    "    with torch.profiler.record_function(\"model_inference\"):\n",
    "        for _ in range(n_runs):\n",
    "            out = bifpn(dummy_input)\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()  # Для корректного измерения на GPU\n",
    "\n",
    "# Выводим сводную таблицу по операциям, сортируя по времени выполнения на CUDA (если GPU)\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=20))\n",
    "\n",
    "# Если хотите сохранить результаты для визуализации в TensorBoard:\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aimv2_1b_patch14_224',\n",
       " 'aimv2_1b_patch14_336',\n",
       " 'aimv2_1b_patch14_448',\n",
       " 'aimv2_3b_patch14_224',\n",
       " 'aimv2_3b_patch14_336',\n",
       " 'aimv2_3b_patch14_448',\n",
       " 'aimv2_huge_patch14_224',\n",
       " 'aimv2_huge_patch14_336',\n",
       " 'aimv2_huge_patch14_448',\n",
       " 'aimv2_large_patch14_224',\n",
       " 'aimv2_large_patch14_336',\n",
       " 'aimv2_large_patch14_448',\n",
       " 'bat_resnext26ts',\n",
       " 'beit_base_patch16_224',\n",
       " 'beit_base_patch16_384',\n",
       " 'beit_large_patch16_224',\n",
       " 'beit_large_patch16_384',\n",
       " 'beit_large_patch16_512',\n",
       " 'beitv2_base_patch16_224',\n",
       " 'beitv2_large_patch16_224',\n",
       " 'botnet26t_256',\n",
       " 'botnet50ts_256',\n",
       " 'caformer_b36',\n",
       " 'caformer_m36',\n",
       " 'caformer_s18',\n",
       " 'caformer_s36',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_medium',\n",
       " 'coat_lite_medium_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_small',\n",
       " 'coat_tiny',\n",
       " 'coatnet_0_224',\n",
       " 'coatnet_0_rw_224',\n",
       " 'coatnet_1_224',\n",
       " 'coatnet_1_rw_224',\n",
       " 'coatnet_2_224',\n",
       " 'coatnet_2_rw_224',\n",
       " 'coatnet_3_224',\n",
       " 'coatnet_3_rw_224',\n",
       " 'coatnet_4_224',\n",
       " 'coatnet_5_224',\n",
       " 'coatnet_bn_0_rw_224',\n",
       " 'coatnet_nano_cc_224',\n",
       " 'coatnet_nano_rw_224',\n",
       " 'coatnet_pico_rw_224',\n",
       " 'coatnet_rmlp_0_rw_224',\n",
       " 'coatnet_rmlp_1_rw2_224',\n",
       " 'coatnet_rmlp_1_rw_224',\n",
       " 'coatnet_rmlp_2_rw_224',\n",
       " 'coatnet_rmlp_2_rw_384',\n",
       " 'coatnet_rmlp_3_rw_224',\n",
       " 'coatnet_rmlp_nano_rw_224',\n",
       " 'coatnext_nano_rw_224',\n",
       " 'convformer_b36',\n",
       " 'convformer_m36',\n",
       " 'convformer_s18',\n",
       " 'convformer_s36',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_atto',\n",
       " 'convnext_atto_ols',\n",
       " 'convnext_atto_rms',\n",
       " 'convnext_base',\n",
       " 'convnext_femto',\n",
       " 'convnext_femto_ols',\n",
       " 'convnext_large',\n",
       " 'convnext_large_mlp',\n",
       " 'convnext_nano',\n",
       " 'convnext_nano_ols',\n",
       " 'convnext_pico',\n",
       " 'convnext_pico_ols',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'convnext_tiny_hnf',\n",
       " 'convnext_xlarge',\n",
       " 'convnext_xxlarge',\n",
       " 'convnext_zepto_rms',\n",
       " 'convnext_zepto_rms_ols',\n",
       " 'convnextv2_atto',\n",
       " 'convnextv2_base',\n",
       " 'convnextv2_femto',\n",
       " 'convnextv2_huge',\n",
       " 'convnextv2_large',\n",
       " 'convnextv2_nano',\n",
       " 'convnextv2_pico',\n",
       " 'convnextv2_small',\n",
       " 'convnextv2_tiny',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'cs3darknet_focus_l',\n",
       " 'cs3darknet_focus_m',\n",
       " 'cs3darknet_focus_s',\n",
       " 'cs3darknet_focus_x',\n",
       " 'cs3darknet_l',\n",
       " 'cs3darknet_m',\n",
       " 'cs3darknet_s',\n",
       " 'cs3darknet_x',\n",
       " 'cs3edgenet_x',\n",
       " 'cs3se_edgenet_x',\n",
       " 'cs3sedarknet_l',\n",
       " 'cs3sedarknet_x',\n",
       " 'cs3sedarknet_xdw',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnet50d',\n",
       " 'cspresnet50w',\n",
       " 'cspresnext50',\n",
       " 'darknet17',\n",
       " 'darknet21',\n",
       " 'darknet53',\n",
       " 'darknetaa53',\n",
       " 'davit_base',\n",
       " 'davit_base_fl',\n",
       " 'davit_giant',\n",
       " 'davit_huge',\n",
       " 'davit_huge_fl',\n",
       " 'davit_large',\n",
       " 'davit_small',\n",
       " 'davit_tiny',\n",
       " 'deit3_base_patch16_224',\n",
       " 'deit3_base_patch16_384',\n",
       " 'deit3_huge_patch14_224',\n",
       " 'deit3_large_patch16_224',\n",
       " 'deit3_large_patch16_384',\n",
       " 'deit3_medium_patch16_224',\n",
       " 'deit3_small_patch16_224',\n",
       " 'deit3_small_patch16_384',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet264d',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn48b',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'eca_nfnet_l3',\n",
       " 'eca_resnet33ts',\n",
       " 'eca_resnext26ts',\n",
       " 'eca_vovnet39b',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet200d',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'ecaresnext26t_32x4d',\n",
       " 'ecaresnext50t_32x4d',\n",
       " 'edgenext_base',\n",
       " 'edgenext_small',\n",
       " 'edgenext_small_rw',\n",
       " 'edgenext_x_small',\n",
       " 'edgenext_xx_small',\n",
       " 'efficientformer_l1',\n",
       " 'efficientformer_l3',\n",
       " 'efficientformer_l7',\n",
       " 'efficientformerv2_l',\n",
       " 'efficientformerv2_s0',\n",
       " 'efficientformerv2_s1',\n",
       " 'efficientformerv2_s2',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b0_g8_gn',\n",
       " 'efficientnet_b0_g16_evos',\n",
       " 'efficientnet_b0_gn',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_g8_gn',\n",
       " 'efficientnet_b3_gn',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_blur_b0',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_h_b5',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'efficientnet_x_b3',\n",
       " 'efficientnet_x_b5',\n",
       " 'efficientnetv2_l',\n",
       " 'efficientnetv2_m',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'efficientnetv2_s',\n",
       " 'efficientnetv2_xl',\n",
       " 'efficientvit_b0',\n",
       " 'efficientvit_b1',\n",
       " 'efficientvit_b2',\n",
       " 'efficientvit_b3',\n",
       " 'efficientvit_l1',\n",
       " 'efficientvit_l2',\n",
       " 'efficientvit_l3',\n",
       " 'efficientvit_m0',\n",
       " 'efficientvit_m1',\n",
       " 'efficientvit_m2',\n",
       " 'efficientvit_m3',\n",
       " 'efficientvit_m4',\n",
       " 'efficientvit_m5',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet19b_slim',\n",
       " 'ese_vovnet19b_slim_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'ese_vovnet39b_evos',\n",
       " 'ese_vovnet57b',\n",
       " 'ese_vovnet99b',\n",
       " 'eva02_base_patch14_224',\n",
       " 'eva02_base_patch14_448',\n",
       " 'eva02_base_patch16_clip_224',\n",
       " 'eva02_enormous_patch14_clip_224',\n",
       " 'eva02_large_patch14_224',\n",
       " 'eva02_large_patch14_448',\n",
       " 'eva02_large_patch14_clip_224',\n",
       " 'eva02_large_patch14_clip_336',\n",
       " 'eva02_small_patch14_224',\n",
       " 'eva02_small_patch14_336',\n",
       " 'eva02_tiny_patch14_224',\n",
       " 'eva02_tiny_patch14_336',\n",
       " 'eva_giant_patch14_224',\n",
       " 'eva_giant_patch14_336',\n",
       " 'eva_giant_patch14_560',\n",
       " 'eva_giant_patch14_clip_224',\n",
       " 'eva_large_patch14_196',\n",
       " 'eva_large_patch14_336',\n",
       " 'fastvit_ma36',\n",
       " 'fastvit_mci0',\n",
       " 'fastvit_mci1',\n",
       " 'fastvit_mci2',\n",
       " 'fastvit_s12',\n",
       " 'fastvit_sa12',\n",
       " 'fastvit_sa24',\n",
       " 'fastvit_sa36',\n",
       " 'fastvit_t8',\n",
       " 'fastvit_t12',\n",
       " 'fbnetc_100',\n",
       " 'fbnetv3_b',\n",
       " 'fbnetv3_d',\n",
       " 'fbnetv3_g',\n",
       " 'flexivit_base',\n",
       " 'flexivit_large',\n",
       " 'flexivit_small',\n",
       " 'focalnet_base_lrf',\n",
       " 'focalnet_base_srf',\n",
       " 'focalnet_huge_fl3',\n",
       " 'focalnet_huge_fl4',\n",
       " 'focalnet_large_fl3',\n",
       " 'focalnet_large_fl4',\n",
       " 'focalnet_small_lrf',\n",
       " 'focalnet_small_srf',\n",
       " 'focalnet_tiny_lrf',\n",
       " 'focalnet_tiny_srf',\n",
       " 'focalnet_xlarge_fl3',\n",
       " 'focalnet_xlarge_fl4',\n",
       " 'gc_efficientnetv2_rw_t',\n",
       " 'gcresnet33ts',\n",
       " 'gcresnet50t',\n",
       " 'gcresnext26ts',\n",
       " 'gcresnext50ts',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_050',\n",
       " 'ghostnet_100',\n",
       " 'ghostnet_130',\n",
       " 'ghostnetv2_100',\n",
       " 'ghostnetv2_130',\n",
       " 'ghostnetv2_160',\n",
       " 'gmixer_12_224',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_b16_224',\n",
       " 'gmlp_s16_224',\n",
       " 'gmlp_ti16_224',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'halonet_h1',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hgnet_base',\n",
       " 'hgnet_small',\n",
       " 'hgnet_tiny',\n",
       " 'hgnetv2_b0',\n",
       " 'hgnetv2_b1',\n",
       " 'hgnetv2_b2',\n",
       " 'hgnetv2_b3',\n",
       " 'hgnetv2_b4',\n",
       " 'hgnetv2_b5',\n",
       " 'hgnetv2_b6',\n",
       " 'hiera_base_224',\n",
       " 'hiera_base_abswin_256',\n",
       " 'hiera_base_plus_224',\n",
       " 'hiera_huge_224',\n",
       " 'hiera_large_224',\n",
       " 'hiera_small_224',\n",
       " 'hiera_small_abswin_256',\n",
       " 'hiera_tiny_224',\n",
       " 'hieradet_small',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w18_ssld',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w48_ssld',\n",
       " 'hrnet_w64',\n",
       " 'inception_next_atto',\n",
       " 'inception_next_base',\n",
       " 'inception_next_small',\n",
       " 'inception_next_tiny',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_035',\n",
       " 'lcnet_050',\n",
       " 'lcnet_075',\n",
       " 'lcnet_100',\n",
       " 'lcnet_150',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'legacy_xception',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_256d',\n",
       " 'levit_384',\n",
       " 'levit_384_s8',\n",
       " 'levit_512',\n",
       " 'levit_512_s8',\n",
       " 'levit_512d',\n",
       " 'levit_conv_128',\n",
       " 'levit_conv_128s',\n",
       " 'levit_conv_192',\n",
       " 'levit_conv_256',\n",
       " 'levit_conv_256d',\n",
       " 'levit_conv_384',\n",
       " 'levit_conv_384_s8',\n",
       " 'levit_conv_512',\n",
       " 'levit_conv_512_s8',\n",
       " 'levit_conv_512d',\n",
       " 'mambaout_base',\n",
       " 'mambaout_base_plus_rw',\n",
       " 'mambaout_base_short_rw',\n",
       " 'mambaout_base_tall_rw',\n",
       " 'mambaout_base_wide_rw',\n",
       " 'mambaout_femto',\n",
       " 'mambaout_kobe',\n",
       " 'mambaout_small',\n",
       " 'mambaout_small_rw',\n",
       " 'mambaout_tiny',\n",
       " 'maxvit_base_tf_224',\n",
       " 'maxvit_base_tf_384',\n",
       " 'maxvit_base_tf_512',\n",
       " 'maxvit_large_tf_224',\n",
       " 'maxvit_large_tf_384',\n",
       " 'maxvit_large_tf_512',\n",
       " 'maxvit_nano_rw_256',\n",
       " 'maxvit_pico_rw_256',\n",
       " 'maxvit_rmlp_base_rw_224',\n",
       " 'maxvit_rmlp_base_rw_384',\n",
       " 'maxvit_rmlp_nano_rw_256',\n",
       " 'maxvit_rmlp_pico_rw_256',\n",
       " 'maxvit_rmlp_small_rw_224',\n",
       " 'maxvit_rmlp_small_rw_256',\n",
       " 'maxvit_rmlp_tiny_rw_256',\n",
       " 'maxvit_small_tf_224',\n",
       " 'maxvit_small_tf_384',\n",
       " 'maxvit_small_tf_512',\n",
       " 'maxvit_tiny_pm_256',\n",
       " 'maxvit_tiny_rw_224',\n",
       " 'maxvit_tiny_rw_256',\n",
       " 'maxvit_tiny_tf_224',\n",
       " 'maxvit_tiny_tf_384',\n",
       " 'maxvit_tiny_tf_512',\n",
       " 'maxvit_xlarge_tf_224',\n",
       " 'maxvit_xlarge_tf_384',\n",
       " 'maxvit_xlarge_tf_512',\n",
       " 'maxxvit_rmlp_nano_rw_256',\n",
       " 'maxxvit_rmlp_small_rw_256',\n",
       " 'maxxvit_rmlp_tiny_rw_256',\n",
       " 'maxxvitv2_nano_rw_256',\n",
       " 'maxxvitv2_rmlp_base_rw_224',\n",
       " 'maxxvitv2_rmlp_base_rw_384',\n",
       " 'maxxvitv2_rmlp_large_rw_224',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b32_224',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l32_224',\n",
       " 'mixer_s16_224',\n",
       " 'mixer_s32_224',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mixnet_xxl',\n",
       " 'mnasnet_050',\n",
       " 'mnasnet_075',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_140',\n",
       " 'mnasnet_small',\n",
       " 'mobilenet_edgetpu_100',\n",
       " 'mobilenet_edgetpu_v2_l',\n",
       " 'mobilenet_edgetpu_v2_m',\n",
       " 'mobilenet_edgetpu_v2_s',\n",
       " 'mobilenet_edgetpu_v2_xs',\n",
       " 'mobilenetv1_100',\n",
       " 'mobilenetv1_100h',\n",
       " 'mobilenetv1_125',\n",
       " 'mobilenetv2_035',\n",
       " 'mobilenetv2_050',\n",
       " 'mobilenetv2_075',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_075',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_large_150d',\n",
       " 'mobilenetv3_rw',\n",
       " 'mobilenetv3_small_050',\n",
       " 'mobilenetv3_small_075',\n",
       " 'mobilenetv3_small_100',\n",
       " 'mobilenetv4_conv_aa_large',\n",
       " 'mobilenetv4_conv_aa_medium',\n",
       " 'mobilenetv4_conv_blur_medium',\n",
       " 'mobilenetv4_conv_large',\n",
       " 'mobilenetv4_conv_medium',\n",
       " 'mobilenetv4_conv_small',\n",
       " 'mobilenetv4_conv_small_035',\n",
       " 'mobilenetv4_conv_small_050',\n",
       " 'mobilenetv4_hybrid_large',\n",
       " 'mobilenetv4_hybrid_large_075',\n",
       " 'mobilenetv4_hybrid_medium',\n",
       " 'mobilenetv4_hybrid_medium_075',\n",
       " 'mobileone_s0',\n",
       " 'mobileone_s1',\n",
       " 'mobileone_s2',\n",
       " 'mobileone_s3',\n",
       " 'mobileone_s4',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_200',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_base_cls',\n",
       " 'mvitv2_huge_cls',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_large_cls',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_small_cls',\n",
       " 'mvitv2_tiny',\n",
       " 'nasnetalarge',\n",
       " 'nest_base',\n",
       " 'nest_base_jx',\n",
       " 'nest_small',\n",
       " 'nest_small_jx',\n",
       " 'nest_tiny',\n",
       " 'nest_tiny_jx',\n",
       " 'nextvit_base',\n",
       " 'nextvit_large',\n",
       " 'nextvit_small',\n",
       " 'nf_ecaresnet26',\n",
       " 'nf_ecaresnet50',\n",
       " 'nf_ecaresnet101',\n",
       " 'nf_regnet_b0',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_regnet_b2',\n",
       " 'nf_regnet_b3',\n",
       " 'nf_regnet_b4',\n",
       " 'nf_regnet_b5',\n",
       " 'nf_resnet26',\n",
       " 'nf_resnet50',\n",
       " 'nf_resnet101',\n",
       " 'nf_seresnet26',\n",
       " 'nf_seresnet50',\n",
       " 'nf_seresnet101',\n",
       " 'nfnet_f0',\n",
       " 'nfnet_f1',\n",
       " 'nfnet_f2',\n",
       " 'nfnet_f3',\n",
       " 'nfnet_f4',\n",
       " 'nfnet_f5',\n",
       " 'nfnet_f6',\n",
       " 'nfnet_f7',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'poolformer_m36',\n",
       " 'poolformer_m48',\n",
       " 'poolformer_s12',\n",
       " 'poolformer_s24',\n",
       " 'poolformer_s36',\n",
       " 'poolformerv2_m36',\n",
       " 'poolformerv2_m48',\n",
       " 'poolformerv2_s12',\n",
       " 'poolformerv2_s24',\n",
       " 'poolformerv2_s36',\n",
       " 'pvt_v2_b0',\n",
       " 'pvt_v2_b1',\n",
       " 'pvt_v2_b2',\n",
       " 'pvt_v2_b2_li',\n",
       " 'pvt_v2_b3',\n",
       " 'pvt_v2_b4',\n",
       " 'pvt_v2_b5',\n",
       " 'rdnet_base',\n",
       " 'rdnet_large',\n",
       " 'rdnet_small',\n",
       " 'rdnet_tiny',\n",
       " 'regnetv_040',\n",
       " 'regnetv_064',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_004_tv',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_008_tv',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_040_sgn',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_080_tv',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'regnety_640',\n",
       " 'regnety_1280',\n",
       " 'regnety_2560',\n",
       " 'regnetz_005',\n",
       " 'regnetz_040',\n",
       " 'regnetz_040_h',\n",
       " 'regnetz_b16',\n",
       " 'regnetz_b16_evos',\n",
       " 'regnetz_c16',\n",
       " 'regnetz_c16_evos',\n",
       " 'regnetz_d8',\n",
       " 'regnetz_d8_evos',\n",
       " 'regnetz_d32',\n",
       " 'regnetz_e8',\n",
       " 'repghostnet_050',\n",
       " 'repghostnet_058',\n",
       " 'repghostnet_080',\n",
       " 'repghostnet_100',\n",
       " 'repghostnet_111',\n",
       " 'repghostnet_130',\n",
       " 'repghostnet_150',\n",
       " 'repghostnet_200',\n",
       " 'repvgg_a0',\n",
       " 'repvgg_a1',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'repvgg_d2se',\n",
       " 'repvit_m0_9',\n",
       " 'repvit_m1',\n",
       " 'repvit_m1_0',\n",
       " 'repvit_m1_1',\n",
       " 'repvit_m1_5',\n",
       " 'repvit_m2',\n",
       " 'repvit_m2_3',\n",
       " 'repvit_m3',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net50d',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2net101d',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet10t',\n",
       " 'resnet14t',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts',\n",
       " 'resnet33ts',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_clip',\n",
       " 'resnet50_clip_gap',\n",
       " 'resnet50_gn',\n",
       " 'resnet50_mlp',\n",
       " 'resnet50c',\n",
       " 'resnet50d',\n",
       " 'resnet50s',\n",
       " 'resnet50t',\n",
       " 'resnet50x4_clip',\n",
       " 'resnet50x4_clip_gap',\n",
       " 'resnet50x16_clip',\n",
       " 'resnet50x16_clip_gap',\n",
       " 'resnet50x64_clip',\n",
       " 'resnet50x64_clip_gap',\n",
       " 'resnet51q',\n",
       " 'resnet61q',\n",
       " 'resnet101',\n",
       " 'resnet101_clip',\n",
       " 'resnet101_clip_gap',\n",
       " 'resnet101c',\n",
       " 'resnet101d',\n",
       " 'resnet101s',\n",
       " 'resnet152',\n",
       " 'resnet152c',\n",
       " 'resnet152d',\n",
       " 'resnet152s',\n",
       " 'resnet200',\n",
       " 'resnet200d',\n",
       " 'resnetaa34d',\n",
       " 'resnetaa50',\n",
       " 'resnetaa50d',\n",
       " 'resnetaa101d',\n",
       " 'resnetblur18',\n",
       " 'resnetblur50',\n",
       " 'resnetblur50d',\n",
       " 'resnetblur101d',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_18',\n",
       " 'resnetv2_18d',\n",
       " 'resnetv2_34',\n",
       " 'resnetv2_34d',\n",
       " 'resnetv2_50',\n",
       " 'resnetv2_50d',\n",
       " 'resnetv2_50d_evos',\n",
       " 'resnetv2_50d_frn',\n",
       " 'resnetv2_50d_gn',\n",
       " 'resnetv2_50t',\n",
       " 'resnetv2_50x1_bit',\n",
       " 'resnetv2_50x3_bit',\n",
       " 'resnetv2_101',\n",
       " 'resnetv2_101d',\n",
       " 'resnetv2_101x1_bit',\n",
       " 'resnetv2_101x3_bit',\n",
       " 'resnetv2_152',\n",
       " 'resnetv2_152d',\n",
       " 'resnetv2_152x2_bit',\n",
       " 'resnetv2_152x4_bit',\n",
       " 'resnext26ts',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_32x16d',\n",
       " 'resnext101_32x32d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'rexnet_300',\n",
       " 'rexnetr_100',\n",
       " 'rexnetr_130',\n",
       " 'rexnetr_150',\n",
       " 'rexnetr_200',\n",
       " 'rexnetr_300',\n",
       " 'sam2_hiera_base_plus',\n",
       " 'sam2_hiera_large',\n",
       " 'sam2_hiera_small',\n",
       " 'sam2_hiera_tiny',\n",
       " 'samvit_base_patch16',\n",
       " 'samvit_base_patch16_224',\n",
       " 'samvit_huge_patch16',\n",
       " 'samvit_large_patch16',\n",
       " 'sebotnet33ts_256',\n",
       " 'sedarknet21',\n",
       " 'sehalonet33ts',\n",
       " 'selecsls42',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'selecsls84',\n",
       " 'semnasnet_050',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'semnasnet_140',\n",
       " 'senet154',\n",
       " 'sequencer2d_l',\n",
       " 'sequencer2d_m',\n",
       " 'sequencer2d_s',\n",
       " 'seresnet18',\n",
       " 'seresnet33ts',\n",
       " 'seresnet34',\n",
       " 'seresnet50',\n",
       " 'seresnet50t',\n",
       " 'seresnet101',\n",
       " 'seresnet152',\n",
       " 'seresnet152d',\n",
       " 'seresnet200d',\n",
       " 'seresnet269d',\n",
       " 'seresnetaa50d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26ts',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'seresnext101_64x4d',\n",
       " 'seresnext101d_32x8d',\n",
       " 'seresnextaa101d_32x8d',\n",
       " 'seresnextaa201d_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnet50',\n",
       " 'skresnet50d',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_s3_base_224',\n",
       " 'swin_s3_small_224',\n",
       " 'swin_s3_tiny_224',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swinv2_base_window8_256',\n",
       " 'swinv2_base_window12_192',\n",
       " 'swinv2_base_window12to16_192to256',\n",
       " 'swinv2_base_window12to24_192to384',\n",
       " 'swinv2_base_window16_256',\n",
       " 'swinv2_cr_base_224',\n",
       " 'swinv2_cr_base_384',\n",
       " 'swinv2_cr_base_ns_224',\n",
       " 'swinv2_cr_giant_224',\n",
       " 'swinv2_cr_giant_384',\n",
       " 'swinv2_cr_huge_224',\n",
       " 'swinv2_cr_huge_384',\n",
       " 'swinv2_cr_large_224',\n",
       " 'swinv2_cr_large_384',\n",
       " 'swinv2_cr_small_224',\n",
       " 'swinv2_cr_small_384',\n",
       " 'swinv2_cr_small_ns_224',\n",
       " 'swinv2_cr_small_ns_256',\n",
       " 'swinv2_cr_tiny_224',\n",
       " 'swinv2_cr_tiny_384',\n",
       " 'swinv2_cr_tiny_ns_224',\n",
       " 'swinv2_large_window12_192',\n",
       " 'swinv2_large_window12to16_192to256',\n",
       " 'swinv2_large_window12to24_192to384',\n",
       " 'swinv2_small_window8_256',\n",
       " 'swinv2_small_window16_256',\n",
       " 'swinv2_tiny_window8_256',\n",
       " 'swinv2_tiny_window16_256',\n",
       " 'test_byobnet',\n",
       " 'test_convnext',\n",
       " 'test_convnext2',\n",
       " 'test_convnext3',\n",
       " 'test_efficientnet',\n",
       " 'test_efficientnet_evos',\n",
       " 'test_efficientnet_gn',\n",
       " 'test_efficientnet_ln',\n",
       " 'test_mambaout',\n",
       " 'test_nfnet',\n",
       " 'test_resnet',\n",
       " 'test_vit',\n",
       " 'test_vit2',\n",
       " 'test_vit3',\n",
       " 'test_vit4',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_xl',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tiny_vit_5m_224',\n",
       " 'tiny_vit_11m_224',\n",
       " 'tiny_vit_21m_224',\n",
       " 'tiny_vit_21m_384',\n",
       " 'tiny_vit_21m_512',\n",
       " 'tinynet_a',\n",
       " 'tinynet_b',\n",
       " 'tinynet_c',\n",
       " 'tinynet_d',\n",
       " 'tinynet_e',\n",
       " 'tnt_b_patch16_224',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_m',\n",
       " 'tresnet_v2_l',\n",
       " 'tresnet_xl',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'visformer_tiny',\n",
       " 'vit_base_mci_224',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch14_dinov2',\n",
       " 'vit_base_patch14_reg4_dinov2',\n",
       " 'vit_base_patch16_18x2_224',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_clip_224',\n",
       " 'vit_base_patch16_clip_384',\n",
       " 'vit_base_patch16_clip_quickgelu_224',\n",
       " 'vit_base_patch16_gap_224',\n",
       " 'vit_base_patch16_plus_240',\n",
       " 'vit_base_patch16_plus_clip_240',\n",
       " 'vit_base_patch16_reg4_gap_256',\n",
       " 'vit_base_patch16_rope_reg1_gap_256',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    # 'resnet50',\n",
    "    'convnextv2_base',\n",
    "    # 'tf_efficientnetv2_s.in21k_ft_in1k',\n",
    "    # 'efficientvit_b0',\n",
    "    features_only=True,\n",
    "    out_indices=(-4, -3, -2, -1),  # C2, C3, C4, C5\n",
    "    pretrained=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 128, 56, 56]), torch.Size([1, 256, 28, 28]), torch.Size([1, 512, 14, 14]), torch.Size([1, 1024, 7, 7])]\n"
     ]
    }
   ],
   "source": [
    "# Пример входных данных (batch_size=1, 3 канала, 224x224)\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Получаем признаки\n",
    "features = model(x)  # Возвращает список [C2, C3, C4, C5]\n",
    "print([f.shape for f in features])  # Пример: [torch.Size([1, 256, 56, 56]), ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128, 256, 512, 1024]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_info.channels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(nn.Module):\n",
    "    def __init__(self, backbone_name='resnet50', out_channels=256):\n",
    "        super().__init__()\n",
    "        # Создаем бэкбон с выводом C2-C5\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone_name,\n",
    "            features_only=True,\n",
    "            out_indices=(1, 2, 3, 4),  # C2, C3, C4, C5\n",
    "            pretrained=True\n",
    "        )\n",
    "        # Получаем количество каналов для каждого уровня\n",
    "        self.channels = self.backbone.feature_info.channels()\n",
    "        \n",
    "        # Lateral 1x1 convolutions для выравнивания каналов\n",
    "        self.lateral_c2 = nn.Conv2d(self.channels[0], out_channels, kernel_size=1)\n",
    "        self.lateral_c3 = nn.Conv2d(self.channels[1], out_channels, kernel_size=1)\n",
    "        self.lateral_c4 = nn.Conv2d(self.channels[2], out_channels, kernel_size=1)\n",
    "        self.lateral_c5 = nn.Conv2d(self.channels[3], out_channels, kernel_size=1)\n",
    "        \n",
    "        # Upsampling\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        \n",
    "        # 3x3 convolutions для сглаживания\n",
    "        self.smooth_p2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.smooth_p3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.smooth_p4 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Получаем признаки C2-C5 из бэкбона\n",
    "        c2, c3, c4, c5 = self.backbone(x)\n",
    "        \n",
    "        # Top-down pathway и lateral connections\n",
    "        p5 = self.lateral_c5(c5)\n",
    "        p4 = self.lateral_c4(c4) + self.up(p5)\n",
    "        p4 = self.smooth_p4(p4)\n",
    "        \n",
    "        p3 = self.lateral_c3(c3) + self.up(p4)\n",
    "        p3 = self.smooth_p3(p3)\n",
    "        \n",
    "        p2 = self.lateral_c2(c2) + self.up(p3)\n",
    "        p2 = self.smooth_p2(p2)\n",
    "        \n",
    "        return p2, p3, p4, p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PANet(nn.Module):\n",
    "    def __init__(self, backbone_name='resnet50', out_channels=256):\n",
    "        super().__init__()\n",
    "        # Инициализация FPN\n",
    "        self.fpn = FPN(backbone_name, out_channels)\n",
    "        \n",
    "        # Дополнительные свёртки для Bottom-Up Pathway\n",
    "        self.down_conv_p2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "        self.down_conv_p3 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "        self.down_conv_p4 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Получаем признаки из FPN\n",
    "        p2, p3, p4, p5 = self.fpn(x)\n",
    "        \n",
    "        # Bottom-Up Pathway (передача признаков вниз)\n",
    "        n2 = p2\n",
    "        n3 = p3 + self.down_conv_p2(n2)\n",
    "        n4 = p4 + self.down_conv_p3(n3)\n",
    "        n5 = p5 + self.down_conv_p4(n4)\n",
    "        \n",
    "        return n2, n3, n4, n5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiFPN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone_name='resnet50',\n",
    "        out_channels=256,\n",
    "        num_layers=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Инициализация бэкбона через timm\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone_name,\n",
    "            features_only=True,\n",
    "            out_indices=(1, 2, 3, 4),  # C2-C5 для ResNet\n",
    "            pretrained=True\n",
    "        )\n",
    "        \n",
    "        # Получаем список каналов из feature_info\n",
    "        self.in_channels_list = self.backbone.feature_info.channels()\n",
    "        \n",
    "        # Адаптационные свёртки\n",
    "        self.lateral_p2 = nn.Conv2d(self.in_channels_list[0], out_channels, 1)\n",
    "        self.lateral_p3 = nn.Conv2d(self.in_channels_list[1], out_channels, 1)\n",
    "        self.lateral_p4 = nn.Conv2d(self.in_channels_list[2], out_channels, 1)\n",
    "        self.lateral_p5 = nn.Conv2d(self.in_channels_list[3], out_channels, 1)\n",
    "        \n",
    "        # BiFPN параметры\n",
    "        self.num_layers = num_layers\n",
    "        self.weights_top_down = nn.ParameterList([\n",
    "            nn.Parameter(torch.ones(2, dtype=torch.float32)) for _ in range(3)\n",
    "        ])\n",
    "        self.weights_bottom_up = nn.ParameterList([\n",
    "            nn.Parameter(torch.ones(2, dtype=torch.float32)) for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        # Обрабатывающие свёртки\n",
    "        self.conv_p2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.conv_p3 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.conv_p4 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.conv_p5 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Извлекаем признаки из бэкбона\n",
    "        features = self.backbone(x)\n",
    "        p2 = self.lateral_p2(features[0])\n",
    "        p3 = self.lateral_p3(features[1])\n",
    "        p4 = self.lateral_p4(features[2])\n",
    "        p5 = self.lateral_p5(features[3])\n",
    "        \n",
    "        # BiFPN обработка\n",
    "        for _ in range(self.num_layers):\n",
    "            # Top-down pathway\n",
    "            p5_td = p5\n",
    "            p4_td = self._weighted_sum(\n",
    "                p4,\n",
    "                F.interpolate(p5_td, size=p4.shape[2:], mode='nearest'),\n",
    "                self.weights_top_down[0]\n",
    "            )\n",
    "            p3_td = self._weighted_sum(\n",
    "                p3,\n",
    "                F.interpolate(p4_td, size=p3.shape[2:], mode='nearest'),\n",
    "                self.weights_top_down[1]\n",
    "            )\n",
    "            p2_td = self._weighted_sum(\n",
    "                p2,\n",
    "                F.interpolate(p3_td, size=p2.shape[2:], mode='nearest'),\n",
    "                self.weights_top_down[2]\n",
    "            )\n",
    "            \n",
    "            # Bottom-up pathway\n",
    "            p2_out = self.conv_p2(p2_td)\n",
    "            p3_out = self.conv_p3(self._weighted_sum(\n",
    "                p3_td,\n",
    "                F.interpolate(p2_out, size=p3_td.shape[2:], mode='nearest'),\n",
    "                self.weights_bottom_up[2]\n",
    "            ))\n",
    "            p4_out = self.conv_p4(self._weighted_sum(\n",
    "                p4_td,\n",
    "                F.interpolate(p3_out, size=p4_td.shape[2:], mode='nearest'),\n",
    "                self.weights_bottom_up[1]\n",
    "            ))\n",
    "            p5_out = self.conv_p5(self._weighted_sum(\n",
    "                p5_td,\n",
    "                F.interpolate(p4_out, size=p5_td.shape[2:], mode='nearest'),\n",
    "                self.weights_bottom_up[0]\n",
    "            ))\n",
    "            \n",
    "            p2, p3, p4, p5 = p2_out, p3_out, p4_out, p5_out\n",
    "        \n",
    "        return p2_out, p3_out, p4_out, p5_out\n",
    "\n",
    "    def _weighted_sum(self, x, y, weights):\n",
    "        w = torch.softmax(weights, dim=0)\n",
    "        return w[0] * x + w[1] * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels, ratio=16):\n",
    "        super().__init__()\n",
    "        self.channel_att = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels//ratio, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels//ratio, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.spatial_att = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, kernel_size=7, padding=3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        channel_mask = self.channel_att(x)\n",
    "        x = x * channel_mask\n",
    "        \n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out = torch.max(x, dim=1, keepdim=True)[0]\n",
    "        spatial_input = torch.cat([avg_out, max_out], dim=1)\n",
    "        spatial_mask = self.spatial_att(spatial_input)\n",
    "        x = x * spatial_mask\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 56, 56]) torch.Size([1, 256, 28, 28]) torch.Size([1, 256, 14, 14]) torch.Size([1, 256, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 224, 224)\n",
    "fpn = FPN()\n",
    "p2, p3, p4, p5 = fpn(x)\n",
    "print(p2.shape, p3.shape, p4.shape, p5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 56, 56]) torch.Size([1, 256, 28, 28]) torch.Size([1, 256, 14, 14]) torch.Size([1, 256, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "panet = PANet()\n",
    "n2, n3, n4, n5 = panet(x)\n",
    "print(n2.shape, n3.shape, n4.shape, n5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 56, 56]) torch.Size([1, 256, 28, 28]) torch.Size([1, 256, 14, 14]) torch.Size([1, 256, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "bifpn = BiFPN(backbone_name='resnet50', out_channels=256, num_layers=2)\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "b2, b3, b4, b5 = bifpn(x)\n",
    "print(b2.shape, b3.shape, b4.shape, b5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 56, 56])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbam = CBAM(256)\n",
    "cbam(p2).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mymodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
